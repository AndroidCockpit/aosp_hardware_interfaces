/*
 * Copyright (C) 2018 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package android.hardware.neuralnetworks@1.2;

import @1.0::Operand;
import @1.0::PerformanceInfo;
import @1.1::OperationType;

/**
 * Operation types.
 *
 * The type of an operation in a model.
 */
enum OperationType : @1.1::OperationType {
    // TODO(b/116445845): Sync docs when all ops are implemented.
    ARGMAX = 38,
    ARGMIN = 39,
    PAD_V2 = 40,
    BBOX_TRANSFORM = 41,
    BIDIRECTIONAL_SEQUENCE_LSTM = 42,
    BIDIRECTIONAL_SEQUENCE_RNN = 43,
    BOX_WITH_NMS_LIMIT = 44,
    CAST = 45,
    CHANNEL_SHUFFLE = 46,
    DETECTION_OUTPUT = 47,
    EMBEDDING_LOOKUP_SPARSE = 48,
    EXP = 49,
    EXPAND_DIMS = 50,
    GATHER = 51,
    GENERATE_PROPOSALS = 52,
    GREATER = 53,
    GREATER_EQUAL = 54,
    GROUPED_CONV_2D = 55,
    HEATMAP_MAX_KEYPOINT = 56,
    LESS = 57,
    LESS_EQUAL = 58,
    LOG = 59,
    LOGICAL_AND = 60,
    LOGICAL_NOT = 61,
    LOGICAL_OR = 62,
    LOG_SOFTMAX = 63,
    MAXIMUM = 64,
    MINIMUM = 65,
    NEG = 66,
    POW = 67,
    PRELU = 68,
    PRIOR_BOX = 69,
    QUANTIZE = 70,
    QUANTIZED_16BIT_LSTM = 71,
    RANDOM_MULTINOMIAL = 72,
    REDUCE = 73,
    ROI_ALIGN = 74,
    RSQRT = 75,
    SELECT = 76,
    SIN = 77,
    SLICE = 78,
    SPARSE_TO_DENSE = 79,
    SPLIT = 80,
    SQRT = 81,
    TILE = 82,
    TOPK_V2 = 83,
    TRANSPOSE_CONV_2D = 84,
    UNIDIRECTIONAL_SEQUENCE_LSTM = 85,
    UNIDIRECTIONAL_SEQUENCE_RNN = 86,
};

/**
 * Describes one operation of the model's graph.
 */
struct Operation {
    /**
     * The operation type.
     */
    OperationType type;

    /**
     * Describes the table that contains the indexes of the inputs of the
     * operation. The offset is the index in the operandIndexes table.
     */
    vec<uint32_t> inputs;

    /**
     * Describes the table that contains the indexes of the outputs of the
     * operation. The offset is the index in the operandIndexes table.
     */
    vec<uint32_t> outputs;
};

/**
 * A Neural Network Model.
 *
 * This includes not only the execution graph, but also constant data such as
 * weights or scalars added at construction time. The only information that
 * may not be known is the shape of the input tensors.
 */
struct Model {
    /**
     * All operands included in the model.
     */
    vec<Operand> operands;

    /**
     * All operations included in the model.
     *
     * The operations are sorted into execution order. Every operand
     * with lifetime MODEL_OUTPUT or TEMPORARY_VARIABLE must be
     * written before it is read.
     */
    vec<Operation> operations;

    /**
     * Input indexes of the model. There must be at least one.
     *
     * Each value corresponds to the index of the operand in "operands".
     */
    vec<uint32_t> inputIndexes;

    /**
     * Output indexes of the model. There must be at least one.
     *
     * Each value corresponds to the index of the operand in "operands".
     */
    vec<uint32_t> outputIndexes;

    /**
     * A byte buffer containing operand data that were copied into the model.
     *
     * An operand's value must be located here if and only if Operand::lifetime
     * equals OperandLifeTime::CONSTANT_COPY.
     */
    vec<uint8_t> operandValues;

    /**
     * A collection of shared memory pools containing operand values.
     *
     * An operand's value must be located here if and only if Operand::lifetime
     * equals OperandLifeTime::CONSTANT_REFERENCE.
     */
    vec<memory> pools;

    /**
     * 'true' indicates TENSOR_FLOAT32 may be calculated with range and/or
     * precision as low as that of the IEEE 754 16-bit floating-point format.
     * 'false' indicates TENSOR_FLOAT32 must be calculated using at least the
     * range and precision of the IEEE 754 32-bit floating-point format.
     */
    bool relaxComputationFloat32toFloat16;
};
